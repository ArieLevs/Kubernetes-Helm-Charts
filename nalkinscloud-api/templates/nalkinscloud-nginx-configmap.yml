{{- $fullName := include "nalkinscloud-api.fullname" . -}}
apiVersion: v1
kind: ConfigMap
metadata:
  name: nginx-config
data:
  default.conf: |

    # This number should be, at maximum, the number of CPU cores on your system.
    # (since nginx doesn't benefit from more than one worker per CPU.)
    #worker_processes 1;


    # Open files
    # How to know how much open files u consume?
    #	ulimit -n   # open files limit per process
    #	lsof | grep nginx | wc -l  # count how many open files an app is taking
    #	cat /proc/sys/fs/file-max    # get max open files allowed

    # Number of file descriptors used for Nginx. This is set in the OS with 'ulimit -n 200000'
    # or using /etc/security/limits.conf
    # Edit /etc/security/limits.conf in order to increase hard and soft opened files allowed
    #	* hard nproc 200000
    #	* soft nproc 200000
    #worker_rlimit_nofile 200000;

    #events {
        # Determines how many clients will be served by each worker process.
        # (Max clients = worker_connections * worker_processes)
        # "Max clients" is also limited by the number of socket connections available on the system (~64k)
        # run ss -s  and u'll see a timewait param
        # The reason for TIMED_WAIT is to handle the case of packets arriving after the socket is closed.
        # This can happen because packets are delayed or the other side just doesn't know that the socket has been closed.
        #
        # From the point of view of the client (nginx)
        #   sysctl net.ipv4.ip_local_port_range
        # 	sysctl net.ipv4.tcp_fin_timeout
        # 	Result:
        #		net.ipv4.ip_local_port_range = 32768 61000
        #		net.ipv4.tcp_fin_timeout = 60  (in other words it causes the TIMED_WAIT)
        # 	(61000 - 32768) / 60 = 470 sockets at any given time
        # 	You can tune these values in order to get more sockets available at a time
        #
        # 	Another option would be:
        #		net.ipv4.tcp_tw_recycle = 1
        #		net.ipv4.tcp_tw_reuse = 1
        # 	In order to allow used sockets in WAIT state, to be reused
        #
        # From the point of view of the server (node process)
        #		sysctl net.core.somaxconn
        # 	It limits the maximum number of requests queued to a listen socket. You can increase it.
        # 	The value of somaxconn is the size of the listen queue.
        # 	Once the connection is established it is no longer in the listen queue and this number doesn't matter.
        # 	If the listen queue is filled up due to to many simultaneous connection requests then additional connections will be refused.
        # 	Defaults to 128. The value should be raised substantially to support bursts of request.
        # 	For example, to support a burst of 1024 requests, set somaxconn to 1024.
        #	net.core.netdev_max_backlog and net.ipv4.tcp_max_syn_backlog
        #worker_connections 1024;


        # Accept as many connections as possible, after nginx gets notification about a new connection.
        # May flood worker_connections, if that option is set too low.
        #multi_accept on;

    #}



    #http {
        # Buffer log writes to speed up IO, or disable them altogether
        #access_log /var/log/nginx/access.log main buffer=16k;
        #access_log on;
        #include       mime.types;
        #default_type  application/octet-stream;

        # Timeout for keep-alive connections. Server will close connections after this time.
        #keepalive_timeout 3;

        # Number of requests a client can make over the keep-alive connection. This is set high for testing.
        #keepalive_requests 100;

        # allow the server to close the connection after a client stops responding. Frees up socket-associated memory.
        #reset_timedout_connection on;

        # send the client a "request timed out" if the body is not loaded by this time. Default 60.
        #client_body_timeout 10;

        # If the client stops reading data, free up the stale client connection after this much time. Default 60.
        #send_timeout 2;

        upstream backend{
            server {{ $fullName }}.{{ .Release.Namespace }}.svc.cluster.local:{{ .Values.service.port }};
        }

        server {
            listen       80;
            #listen       443 ssl;
            server_name {{ .Values.nginx.configs.serverName }};

            error_log /dev/stdout debug;

            #ssl_certificate     /etc/nginx/pki/server.crt;
            #ssl_certificate_key /etc/nginx/pki/server.key;

            location = /favicon.ico { access_log off; log_not_found off; }

            location /static/ {
                autoindex on;
                alias {{ .Values.nginx.configs.staticRoot }};
            }

            location / {
                autoindex on;
                try_files $uri @proxy;
            }

            location @proxy {
                proxy_set_header X-Real-IP $remote_addr;
                proxy_set_header X-Forwarded-For $proxy_add_X_forwarded_for;
                proxy_set_header Host $host;

                proxy_pass http://backend;

            }
        }
    #}